---
title       : CRM Opportunity Object
subtitle    : Descriptive and Text mining Analysis
author      : Romina Pardo
job         : 
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}

widgets     : [mathjax, quiz, bootstrap, interactive] # {mathjax, quiz, bootstrap}
ext_widgets : {rCharts: [libraries/nvd3, libraries/leaflet, libraries/dygraphs]}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
logo        : IDB-logo.png
biglogo     : IDB-logo.png
assets      : {assets: ../../assets}
--- 

<style type="text/css">
body {background:white transparent;
}
</style>
---
<!--
{r, results="hide"} - The chunks is run but all results are hidden. The code shows in the doc, however.
{r, include=FALSE} - the code is run but neither the code or the results are shown
{r, echo=FALSE} - The code is not shown, but results are
If you want a code chunk to run and not produce console output but you DO want to see the resulting graphs, you can sink() to /dev/null` like the following:

sink("/dev/null")
Desc(mtcars)
sink(); 
--> 

## Text mining analysis: Procedure and Overview

I.  Load Libraries and data sets.

II. Filter out all records with missing description.

      ```{r, DataPrep1, include=FALSE}
      #-- Load Libraries and data sets -- #
      library(slidify)
      library(textcat)
      library(tm)
      library(udpipe)
      library(lattice)
      library(RColorBrewer)
      library(igraph)
      library(ggraph)
      library(ggplot2)
      library(textrank)
      library(wordcloud)
      library(xlsx)
      library(summarytools)
      load("~/RData/RP_Opportunity_29-Jul-2019 11.16.Rda")
      #-- Fonts
      library(extrafont)
      #font_import() only do this one time - it takes a while
      loadfonts(device = "win")
      windowsFonts(Arial=windowsFont("TT Arial")) 
      library(tidyverse)
      theme_set(theme_bw(base_size=12, base_family = 'Arial')+ 
            theme(panel.grid.major = element_blank(),
                  panel.grid.minor = element_blank()))
      #-- Keep Description and other relevant fields --#
      df<- Opportunity[, c("Id", "Name","Description", "Country_of_Administration__c", "Country_of_the_owner__c", "CreatedDate",
                            "CloseDate", "Opportunity_Iniciators__c", "Sector_Global__c","StageName", "Type")]
      #-- Filter out all records with missing description --##
      df<-df[!is.na(df$Description),]
      #-- Detect language of Description and create Nominal variable Language  --##
      df$Language <-  as.factor(textcat(df$Description))
      ```
III. View frequencies of languages in description field.

      ```{r, DataPrep2, echo=FALSE}
      #-- Visualize the frequencies of languages --##
      table(df$Language)
      df1<-subset(df,!(df$Language %in% c("english","spanish", "french")))
      df1<-subset(df1,select=c("Id", "Description", "Language"))
      write.xlsx(df, "Opportunity.xlsx")
      #write.xlsx(df1, "OppDesc1.xlsx")
      ```
IV. Create separate data sets for descriptions in english and spanish. Prepare description Field for Text Mining Analysis:
lowercase, remove stopwords.

      ```{r, DataPrep3, echo=FALSE}
      #-- Convert Description field to lowercase. --#
      #-- Create separate df for descriptions in english and in spanish, remove stopwords and set field type to factor --#
      df$Description <- as.character(tolower(df$Description))
      df_spa<-subset(df,(df$Language =="spanish"))
      df_spa$Description <-as.factor(removeWords(df_spa$Description, stopwords("spanish")))
      df_eng<-subset(df,(df$Language =="english"))
      df_eng$Description <-as.factor(removeWords(df_eng$Description, stopwords("english"))) 
      ```

&nbsp;

V. [Download Description in languages other than english, spanish or french.](./OppDesc.xlsx)


---


## Previous results of Descriptive Analysis

&nbsp;

1. 75% of Opportunities have been generated by Ecuador, Jamaica, Mexico and Uruguay.
&nbsp;
2. IDB has initiated 50%. 25% has NA initiator.
&nbsp;
3. 26% of Opportunities are in Education Sector, 20% are NA. The 3rd postion is shared by multisector, Financial Markets and Water and Sanitation, each with 10% of Opportunities.
&nbsp;
4. 29% of Opportunities are Closed (10% Lost and 9% won). 
&nbsp;
 
 [Download Descriptive Analysis.](./Opportunity.xlsx)

---  
  
## English POS Tagging
  
&nbsp;

**Use of pre-trained open- sourced models provided by UDpipe Community:**
  
  https://cran.r-project.org/web/packages/udpipe/vignettes/udpipe-annotation.html

&nbsp;

**UPOS (Universal Parts of Speech) frequency of occurrence:**
  
  &nbsp;
```{r, POSTaggingModelEng, include=FALSE}
df<-df_eng
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
x <- udpipe_annotate(ud_model, x = df$Description, doc_id = df$Id)
x <- as.data.frame(x)
stats <- txt_freq(x$upos)
```

```{r, POSTaggingModelResultsEng, echo=FALSE}
head(stats,3)
stats <- txt_freq(x$upos)
```

---

<!-- ## English POS Tagging  bar chart -->

<!-- ```{r, POSTaggingBar, echo=FALSE} -->
<!-- stats$key <- factor(stats$key, levels = rev(stats$key)) -->
<!-- barchart(key ~ freq, data = stats, col = "yellow", -->
<!--          main = "UPOS (Universal Parts of Speech)\n frequency of occurrence", -->
<!--          xlab = "Freq") -->
<!-- ``` -->

<!-- --- .class #id -->

## English POS: Nouns

Most Occurring Nouns in Descriptions

```{r, NounEng, echo=FALSE}
stats <- subset(x, upos %in% c("NOUN"))
stats <- txt_freq(stats$token)
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 10),col=colorRampPalette(brewer.pal(9, "Blues"))(10), xlab = "Frequency")
```

---

## English POS: Adjectives

### Most Occurring Adjectives in Descriptions

  ```{r, AdjEng, echo=FALSE}
  stats <- subset(x, upos %in% c("ADJ"))
  stats <- txt_freq(stats$token)
  stats$key <- factor(stats$key, levels = rev(stats$key))
  barchart(key ~ freq, data = head(stats, 10), col=colorRampPalette(brewer.pal(9,"Oranges"))(10), xlab = "Frequency")
  ```

---


## English POS: Verbs

### Most Occurring Verbs in Descriptions

 ```{r, VerbEng, echo=FALSE}
 stats <- subset(x, upos %in% c("VERB"))
 stats <- txt_freq(stats$token)
 stats$key <- factor(stats$key, levels = rev(stats$key))
 barchart(key ~ freq, data = head(stats, 10), col=colorRampPalette(brewer.pal(9,"Greens"))(10), xlab = "Frequency (quantity of terms)")
      ```

--- 

## RAKE: Rapid Automatic Keyword Extraction algorithm

&nbsp;

* Unsupervised algorithm that scores key phrases in a body of text by analyzing the frequency of each word appearance and its co-occurrence with other words in the text.

&nbsp;

* It looks for a contiguous sequence of relevant words searching for keywords.

&nbsp;

* For each word of any candidate keyword,it calculates a score which is the ratio of the word degree (how many times it co-occurs with other words) to the word frequency.

&nbsp;

* A RAKE score for the full candidate keyword is calculated by summing up the scores of each of the words which define the candidate keyword

--- 

### **English keywords Using RAKE**

```{r, RAKEEng, echo=FALSE}
stats <- keywords_rake(x = x, term = "lemma", group = "doc_id",
                       relevant = x$upos %in% c("NOUN", "ADJ"))
stats$key <- factor(stats$keyword, levels = rev(stats$keyword))
barchart(key ~ rake, data = head(subset(stats, freq > 1),5 ), col=colorRampPalette(brewer.pal(12,"Paired"))(5),
         main = "Keywords",
         xlab = "RAKE Score")
```

--- 


### **English top noun - verbs pairs as keyword pairs**

<!-- ## Using a sequence of POS tags (noun phrases / verb phrases) -->
<!-- # This function allows to extract phrases, like simple noun phrases, complex noun phrases or any -->
<!-- # exact sequence of parts of speech tag patterns. -->
<!-- # An example use case of this is to get all text where an adjective is followed by a noun or for example -->
<!-- # to get all phrases consisting of a preposition which is followed by a noun which is next followed by -->
<!-- # a verb. -->
<!-- # extract phrases. These are defined as a sequence of Parts of Speech Tags. -->
<!-- # Common type of phrases are noun phrases or verb phrases. -->
<!-- # How does this work? Parts of Speech tags are recoded to one of the following one-letters: -->
<!-- #   (A: adjective, C: coordinating conjuction, D: determiner, M: modifier of verb, N: noun or proper noun, P: preposition). -->
<!-- # Next you can define a regular expression to indicate a sequence of parts of speech tags which you want to extract from the text. -->

<!-- ## Simple noun phrases (a adjective+noun, pre/postposition, optional determiner and another adjective+noun) -->
```{r, TOPEng, echo=FALSE}
x$phrase_tag <- as_phrasemachine(x$upos, type = "upos")
stats <- keywords_phrases(x = x$phrase_tag, term = tolower(x$token),
                          pattern = "(A|N)*N(P+D*(A|N)*N)*",
                          is_regex = TRUE, detailed = FALSE)
stats <- subset(stats, ngram > 1 & freq > 2)
stats$key <- factor(stats$keyword, levels = rev(stats$keyword))
barchart(key ~ freq, data = head(stats, 35), col = colorRampPalette(brewer.pal(12,"Set3"))(35),
         main = "Keywords with Simple Noun Phrases", xlab = "Frequency of Terms")
```

--- 



### **Co-occurrences: Frequency of words -nouns & adjectives - in the same sentence**

```{r, COOC1Eng, echo=FALSE, results='hide', message=FALSE, warning=FALSE}

stats <- cooccurrence(x = subset(x, upos %in% c("NOUN", "ADJ")),
                      term = "lemma", group = c("doc_id", "paragraph_id", "sentence_id"))

# Visualize network plot #
wordnetwork <- head(stats, 30)
wordnetwork <- graph_from_data_frame(wordnetwork)
ggraph(wordnetwork, layout = "fr") +
  geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = "light blue") +
  geom_node_text(aes(label = name), col = "darkblue", size = 4) +
  theme_graph(base_family = "Arial") +
  theme(legend.position = "none")
```

--- 

### **Co-occurrences: Frequency of words -nouns & adjectives - following one another**

```{r, COOC2Eng, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
stats <- cooccurrence(x = x$lemma,
                      relevant = x$upos %in% c("NOUN", "ADJ"))
# Visualize network plot #
wordnetwork <- head(stats, 30)
wordnetwork <- graph_from_data_frame(wordnetwork)
ggraph(wordnetwork, layout = "fr") +
  geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = "light blue") +
  geom_node_text(aes(label = name), col = "darkblue", size = 4) +
  theme_graph(base_family = "Arial") +
  theme(legend.position = "none")
```

--- 

### **Co-occurrences: Frequency of words -nouns & adjectives - following one another skipping up to 2 words in between**

```{r, COOC3Eng, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
stats <- cooccurrence(x = x$lemma,
                      relevant = x$upos %in% c("NOUN", "ADJ"), skipgram = 2)
# Visualize network plot #
wordnetwork <- head(stats, 30)
wordnetwork <- graph_from_data_frame(wordnetwork)
ggraph(wordnetwork, layout = "fr") +
  geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = "light blue") +
  geom_node_text(aes(label = name), col = "darkblue", size = 4) +
  theme_graph(base_family = "Arial") +
  theme(legend.position = "none")
```

--- 


## English Textrank (word network ordered by Google Pagerank)

### Unigram and ngrams with frequency over 2
<!-- Textrank is an algorithm implemented in the textrank R package. The algorithm allows to summarise text and as well allows to extract keywords. This is done by constructing a word network by looking if words are following one another. On top of that network the 'Google Pagerank' algorithm is applied to extract relevant words after which relevant words which are following one another are combined to get keywords. -->

```{r fig.width=12,fig.height=6,fig.align="center",out.width="1500px", TextRankEng, echo=FALSE}
par(mfrow=c(1,2))
stats <- textrank_keywords(x$lemma, relevant = x$upos %in% c("NOUN", "ADJ"),
                           ngram_max = 10, sep = " ")

stats <- subset(stats$keywords, ngram = 1 & freq >= 2)


pal = brewer.pal(8,"Dark2")
wordcloud(words = stats$keyword, freq = stats$freq, scale = c(3,.1),
          random.order = T,
          random.color = T,
          colors = colorRampPalette(pal)(8))
stats <- textrank_keywords(x$lemma, relevant = x$upos %in% c("NOUN", "ADJ"),
                           ngram_max = 10, sep = " ")

stats <- subset(stats$keywords, ngram >= 2 & freq >= 2)
wordcloud(words = stats$keyword, freq = stats$freq, scale = c(1,.05),
          random.order = T,
          random.color = T,
          colors = colorRampPalette(pal)(8))
```


---  
  
## Spanish POS Tagging
  
&nbsp;

**Use of pre-trained open- sourced models provided by UDpipe Community:**
  
  https://cran.r-project.org/web/packages/udpipe/vignettes/udpipe-annotation.html

&nbsp;

**UPOS (Universal Parts of Speech) frequency of occurrence:**
  
  &nbsp;

```{r, POSTaggingModelSpa, include=FALSE}
df<-df_spa
ud_model <- udpipe_download_model(language = "spanish")
ud_model <- udpipe_load_model(ud_model$file_model)
x <- udpipe_annotate(ud_model, x = df$Description, doc_id = df$Id)
x <- as.data.frame(x)
stats <- txt_freq(x$upos)
```

```{r, POSTaggingModelResultsSpa, echo=FALSE}
head(stats,3)
stats <- txt_freq(x$upos)
```

--- 


## Spanish POS: Nouns

Most Occurring Nouns in Descriptions

```{r, NounSpa, echo=FALSE}
stats <- subset(x, upos %in% c("NOUN"))
stats <- txt_freq(stats$token)
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 10),col=colorRampPalette(brewer.pal(9, "Blues"))(10), xlab = "Frequency")
```

--- 

## Spanish POS: Adjectives

### Most Occurring Adjectives in Descriptions

```{r, AdjSpa, echo=FALSE}
stats <- subset(x, upos %in% c("ADJ"))
stats <- txt_freq(stats$token)
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 10), col=colorRampPalette(brewer.pal(9,"Oranges"))(10), xlab = "Frequency")
```

--- 


## Spanish POS: Verbs

### Most Occurring Verbs in Descriptions

```{r, VerbSpa, echo=FALSE}
stats <- subset(x, upos %in% c("VERB"))
stats <- txt_freq(stats$token)
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 10), col=colorRampPalette(brewer.pal(9,"Greens"))(10), xlab = "Frequency (quantity of terms)")
```

--- 


### **Spanish keywords Using RAKE**

```{r, RAKESpa, echo=FALSE}
stats <- keywords_rake(x = x, term = "lemma", group = "doc_id",
                       relevant = x$upos %in% c("NOUN", "ADJ"))
stats$key <- factor(stats$keyword, levels = rev(stats$keyword))
barchart(key ~ rake, data = head(subset(stats, freq > 1),5 ), col=colorRampPalette(brewer.pal(12,"Paired"))(5),
         main = "Keywords",
         xlab = "RAKE Score")
```

--- 


### **Spanish top noun - verbs pairs as keyword pairs**


  ```{r, TOPSpa, echo=FALSE}
x$phrase_tag <- as_phrasemachine(x$upos, type = "upos")
stats <- keywords_phrases(x = x$phrase_tag, term = tolower(x$token),
                          pattern = "(A|N)*N(P+D*(A|N)*N)*",
                          is_regex = TRUE, detailed = FALSE)
stats <- subset(stats, ngram > 1 & freq > 2)
stats$key <- factor(stats$keyword, levels = rev(stats$keyword))
barchart(key ~ freq, data = head(stats, 35), col = colorRampPalette(brewer.pal(12,"Set3"))(35),
         main = "Keywords with Simple Noun Phrases", xlab = "Frequency of Terms")
```

--- 



### **Co-occurrences: Frequency of words -nouns & adjectives - in the same sentence**

```{r, COOC1Spa, echo=FALSE, results='hide', message=FALSE, warning=FALSE}

stats <- cooccurrence(x = subset(x, upos %in% c("NOUN", "ADJ")),
                      term = "lemma", group = c("doc_id", "paragraph_id", "sentence_id"))

# Visualize network plot #
wordnetwork <- head(stats, 30)
wordnetwork <- graph_from_data_frame(wordnetwork)
ggraph(wordnetwork, layout = "fr") +
  geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = "light blue") +
  geom_node_text(aes(label = name), col = "darkblue", size = 4) +
  theme_graph(base_family = "Arial") +
  theme(legend.position = "none")
```

--- 

### **Co-occurrences: Frequency of words -nouns & adjectives - following one another**

```{r, COOC2Spa, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
stats <- cooccurrence(x = x$lemma,
                      relevant = x$upos %in% c("NOUN", "ADJ"))
# Visualize network plot #
wordnetwork <- head(stats, 30)
wordnetwork <- graph_from_data_frame(wordnetwork)
ggraph(wordnetwork, layout = "fr") +
  geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = "light blue") +
  geom_node_text(aes(label = name), col = "darkblue", size = 4) +
  theme_graph(base_family = "Arial") +
  theme(legend.position = "none")
```

---

### **Co-occurrences: Frequency of words -nouns & adjectives - following one another skipping up to 2 words in between**

```{r, COOC3Spa, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
stats <- cooccurrence(x = x$lemma,
                      relevant = x$upos %in% c("NOUN", "ADJ"), skipgram = 2)
# Visualize network plot #
wordnetwork <- head(stats, 30)
wordnetwork <- graph_from_data_frame(wordnetwork)
ggraph(wordnetwork, layout = "fr") +
  geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = "light blue") +
  geom_node_text(aes(label = name), col = "darkblue", size = 4) +
  theme_graph(base_family = "Arial") +
  theme(legend.position = "none")
```

---


## Spanish Textrank (word network ordered by Google Pagerank)

### Unigram and ngrams with frequency over 2
<!-- Textrank is an algorithm implemented in the textrank R package. The algorithm allows to summarise text and as well allows to extract keywords. This is done by constructing a word network by looking if words are following one another. On top of that network the 'Google Pagerank' algorithm is applied to extract relevant words after which relevant words which are following one another are combined to get keywords. -->
  
  ```{r fig.width=12,fig.height=6,fig.align="center",out.width="1500px", TextRankSpa, echo=FALSE}
par(mfrow=c(1,2))
stats <- textrank_keywords(x$lemma, relevant = x$upos %in% c("NOUN", "ADJ"),
                           ngram_max = 10, sep = " ")

stats <- subset(stats$keywords, ngram = 1 & freq >= 2)


pal = brewer.pal(8,"Dark2")
wordcloud(words = stats$keyword, freq = stats$freq, scale = c(2,.1),
          random.order = T,
          random.color = T,
          colors = colorRampPalette(pal)(8))
stats <- textrank_keywords(x$lemma, relevant = x$upos %in% c("NOUN", "ADJ"),
                           ngram_max = 10, sep = " ")

stats <- subset(stats$keywords, ngram >= 2 & freq >= 2)
wordcloud(words = stats$keyword, freq = stats$freq, scale = c(3,.1),
          random.order = T,
          random.color = T,
          colors = colorRampPalette(pal)(8))
```

---






